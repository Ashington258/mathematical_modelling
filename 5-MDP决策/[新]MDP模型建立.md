<!--
 * @Author: Ashington ashington258@proton.me
 * @Date: 2024-09-08 02:20:17
 * @LastEditors: Ashington ashington258@proton.me
 * @LastEditTime: 2024-09-08 02:20:23
 * @FilePath: \mathematical_modelling\5-MDP决策\[新]MDP模型建立.md
 * @Description: 请填写简介
 * 联系方式:921488837@qq.com
 * Copyright (c) 2024 by ${git_name_email}, All Rights Reserved. 
-->
为了建立问题三的完整马尔可夫决策过程（MDP）模型，我们将定义模型的各个关键组件，包括状态空间、行动空间、状态转移概率、奖励函数，并给出求解最优策略的步骤。以下是问题三的完整 MDP 模型：

### 1. MDP 模型的定义

MDP 模型通常用一个四元组 \( (S, A, P, R) \) 表示，其中：

- **状态空间 \( S \)：** 包含生产过程中所有可能的状态，定义为一个多维向量，表示零配件、半成品和成品的状态。
  
- **行动空间 \( A \)：** 包含在每个状态下可以采取的所有可能行动，包括检测、不检测、装配、销售和拆解等操作。

- **状态转移概率 \( P(s' | s, a) \)：** 描述了在状态 \( s \) 下采取行动 \( a \) 后，系统转移到下一个状态 \( s' \) 的概率。

- **奖励函数 \( R(s, a) \)：** 定义为在状态 \( s \) 下采取行动 \( a \) 所获得的收益或成本，目标是最大化长期回报。

### 2. 各组件的详细定义

#### **状态空间 \( S \)：**

每个状态 \( s \) 表示为：

\[
s = (s_1, s_2, \ldots, s_8, s_9, s_{10}, s_{11}, s_{12})
\]

其中：
- \( s_1 \) 到 \( s_8 \)：分别表示8个零配件的状态，包括数量、质量（合格或次品）、检测状态（已检测或未检测）。
- \( s_9 \) 到 \( s_{11} \)：分别表示3个半成品的状态，包含当前工序进度和质量状态。
- \( s_{12} \)：表示成品的状态，包括数量、质量状态、是否准备进入市场等。

#### **行动空间 \( A \)：**

行动空间包括以下操作：

- **检测：** \( \text{Inspect}_{i} \) 对指定的零配件、半成品或成品进行检测。
- **不检测：** \( \text{DoNotInspect}_{i} \) 不对指定的零配件、半成品进行检测，直接进行下一步。
- **装配：** \( \text{Assemble}_{i,j} \) 将指定的零配件组合成半成品或将半成品组合成成品。
- **销售：** \( \text{Sell}_{12} \) 销售成品。
- **拆解：** \( \text{Disassemble}_{12} \) 拆解不合格成品，回收零配件以便重新使用。

#### **状态转移概率 \( P(s' | s, a) \)：**

状态转移概率的定义需要考虑每个行动对状态的影响，以及各个环节的不确定性因素，如次品率、检测准确率等：

1. **检测行动的转移概率：**
   - \( P(s' | s, \text{Inspect}_{i}) = p_{\text{合格}} \times \text{检测准确率} \) 或 \( (1 - p_{\text{合格}}) \times \text{误检率} \)，具体取决于检测结果的正确性。
   
2. **装配行动的转移概率：**
   - \( P(s' | s, \text{Assemble}_{i,j}) = p_{\text{装配成功}} \) 表示成功装配成半成品或成品。
   
3. **销售行动的转移概率：**
   - \( P(s' | s, \text{Sell}_{12}) = p_{\text{合格}} \times p_{\text{成功销售}} \)，包括合格概率和市场接受概率。
   
4. **拆解行动的转移概率：**
   - \( P(s' | s, \text{Disassemble}_{12}) = p_{\text{拆解成功}} \)，指拆解成功回收零配件的概率。

#### **奖励函数 \( R(s, a) \)：**

根据问题二提供的成本和收益模型，奖励函数综合考虑生产过程中的各种成本和收益：

\[
R(s, a) = \text{销售收益} - (\text{零配件购买成本} + \text{检测成本} + \text{装配成本} + \text{拆解费用} + \text{调换损失})
\]

- **具体公式：**

  \[
  R(s, a) = s^f \cdot n^f - \left( n^c \left( \sum_{i=1}^{8} c_{pi}^c + \sum_{i=1}^{8} x_i \cdot c_{di}^c \right) + n^f \left( c_d^f \cdot y + c_a^f \cdot z + c_s \cdot y + c_s^f \right) \right)
  \]

  - \( s^f \)：成品售价
  - \( n^f \)：合格成品数量
  - \( n^c \)：零配件数量
  - \( c_{pi}^c \)：零配件购买单价
  - \( c_{di}^c \)：零配件检测成本
  - \( c_d^f \)：成品检测成本
  - \( c_a^f \)：成品拆解费用
  - \( c_s \)：调换损失
  - \( c_s^f \)：装配成本

### 3. 求解最优策略 \( \pi^* \)

#### **步骤 1：初始化**

- 初始化所有状态的值函数 \( V(s) = 0 \)。

#### **步骤 2：策略迭代或值迭代**

- **值迭代：** 使用贝尔曼方程更新值函数：

  \[
  V(s) = \max_{a \in A} \left( R(s, a) + \gamma \sum_{s' \in S} P(s' | s, a) V(s') \right)
  \]

  其中，\(\gamma\) 是折扣因子，用于平衡当前和未来收益。

- **策略迭代：** 交替进行策略评估和策略改进：

  - **策略评估：** 计算在当前策略下的值函数。
  
  - **策略改进：** 更新策略，使其在每个状态下选择能够最大化长期回报的行动。

#### **步骤 3：收敛**

- 重复值迭代或策略迭代步骤，直到值函数 \( V(s) \) 收敛，确定最优值函数 \( V^*(s) \)。

#### **步骤 4：确定最优策略 \( \pi^* \)**

- 根据最优值函数，确定每个状态下的最优行动：

  \[
  \pi^*(s) = \arg\max_{a \in A} \left( R(s, a) + \gamma \sum_{s' \in S} P(s' | s, a) V^*(s') \right)
  \]

### 4. 可视化与验证

- **可视化：** 通过图形化展示状态转移和策略路径，验证最优策略的合理性。
- **敏感性分析：** 评估模型对关键参数（如次品率、检测准确率等）的敏感性，确保策略在不同条件下的鲁棒性。

### 总结

通过构建完整的 MDP 模型并求解最优策略 \( \pi^* \)，可以优化生产过程中的决策路径，最大化整体收益或最小化成本。这个模型综合了生产过程中的各种因素，并通过动态规划方法找到最佳策略，使企业能够在复杂的生产网络中作出最佳决策。